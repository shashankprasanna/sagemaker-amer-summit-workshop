{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries including SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update SageMaker SDK if necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(sagemaker.__version__.split('.')[0]) != 2:\n",
    "    !pip install sagemaker==2.24.1\n",
    "    print(\"Updating SageMakerVersion. Please restart the kernel\")\n",
    "else:\n",
    "    print(\"SageMaker SDK version is good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directories in the SageMaker default bucket for this tutorialÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bucket = sagemaker_session.default_bucket()  # Alterantively you can use our custom bucket here.\n",
    "\n",
    "prefix = 'sagemaker-tutorial'  # use this prefix to store all files pertaining to this workshop.\n",
    "data_prefix = prefix + '/data'\n",
    "\n",
    "training_job_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "bias_report_output_path = f's3://{default_bucket}/{prefix}/clarify-output/bias'\n",
    "explainability_output_path = f's3://{default_bucket}/{prefix}/clarify-output/explainability'\n",
    "batch_output = f's3://{default_bucket}/{prefix}/transform/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code snippet to download the dataset to the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_dir = './data'\n",
    "!mkdir $local_data_dir\n",
    "# !wget -O ./data/default_of_credit_card.xls  https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\n",
    "!wget -O ./data/default_of_credit_card.xls https://raw.githubusercontent.com/Amirosimani/sm-tutorial/master/2%20hour/data/default_of_credit_card.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as dataframe\n",
    "df = pd.read_excel('./data/default_of_credit_card.xls', header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of missing values in the data: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the bar graph customer gender\n",
    "df['SEX'].value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0,1], ['Male', 'Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the age distribution\n",
    "plt.hist(df['AGE'], bins=30)\n",
    "plt.xlabel('Clients Age Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df)\n",
    "cols.insert(0, cols.pop(cols.index('default payment next month')))\n",
    "df = df.loc[:, cols]\n",
    "\n",
    "df.rename(columns={\"default payment next month\": \"LABEL\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the raw csv data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/dataset.csv', index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/dataset.csv', \n",
    "                                         bucket=default_bucket,\n",
    "                                         key_prefix=data_prefix)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Split DataFrame into Train, Validation & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=random_state)\n",
    "X_train, X_val = train_test_split(X_test, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f'{local_data_dir}/train.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/train.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_data_uri = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.to_csv(f'{local_data_dir}/validation.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/validation.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_data_uri = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_s3 = X_test.drop(columns=['LABEL'])\n",
    "X_test_s3.to_csv(f'{local_data_dir}/test.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/test.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_data_uri = response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Use XGBoost as a built-in algorithm\n",
    "\n",
    "The XGBoost (eXtreme Gradient Boosting) is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm that attempts to accurately predict a target variable by combining an ensemble of estimates from a set of simpler and weaker models. The XGBoost algorithm performs well in machine learning competitions because of its robust handling of a variety of data types, relationships, distributions, and the variety of hyperparameters that you can fine-tune. You can use XGBoost for regression, classification (binary and multiclass), and ranking problems.\n",
    "\n",
    "Use the XGBoost built-in algorithm to build an XGBoost training container as shown in the following code example. You can automatically spot the XGBoost built-in algorithm image URI using the SageMaker image_uris.retrieve API (or the `image_uris` API if using Amazon SageMaker Python SDK version 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the XGBoost image URI, you can use the XGBoost container to construct an estimator using the SageMaker Estimator API and initiate a training job. This XGBoost built-in algorithm mode does not incorporate your own XGBoost training script and runs directly on the input datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"num_round\": \"50\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": random_state\n",
    "}\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=training_job_output_path,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Creating XGBoost model with Hyperparameter Tunining\n",
    "\n",
    "We will tune four hyperparameters in this examples:\n",
    "\n",
    "* eta: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "* alpha: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "* min_child_weight: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this simply corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is.\n",
    "* max_depth: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'max_depth': IntegerParameter(1, 10),\n",
    "                         'eta': ContinuousParameter(0, 1),\n",
    "                         'gamma': ContinuousParameter(0, 5),\n",
    "                         'alpha': ContinuousParameter(0, 2),                         \n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: validation:auc and train:auc, and we elected to monitor validation:auc as you can see below. In this case, we only need to specify the metric name and do not need to provide regex. If you bring your own algorithm, your algorithm emits metrics by itself. In that case, you'll need to add a MetricDefinition object here to define the format of those metrics through regex, so that SageMaker knows how to extract those metrics from your CloudWatch logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a HyperparameterTuner object, to which we pass:\n",
    "\n",
    "* The XGBoost estimator we created above\n",
    "* Our hyperparameter ranges\n",
    "* Objective metric name and definition\n",
    "* Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=4,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "# You can increase the number of jobs, etc. I set them to 10, 4 for the demo purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Launch Hyperparameter Tuning job\n",
    "\n",
    "Now we can launch a hyperparameter tuning job by calling fit() function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=\"text/csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "tuner.fit({'train': train_input,\n",
    "           'validation': validation_input\n",
    "          }\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=tuner.best_training_job())\n",
    "training_job_info['HyperParameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Regsiter the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{training_job_info['TrainingJobName']}-mod\"\n",
    "print(model_name)\n",
    "\n",
    "model_data = training_job_info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\"Image\": xgboost_container, \"ModelDataUrl\": model_data}\n",
    "\n",
    "create_model_response = sagemaker_session.create_model(\n",
    "    name=model_name,\n",
    "    role=sagemaker_role,\n",
    "    container_defs=primary_container\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fairness and Explainability with SageMaker Clarify\n",
    "Amazon SageMaker Clarify helps improve your machine learning models by detecting potential bias and helping explain how these models make predictions. The fairness and explainability functionality provided by SageMaker Clarify helps AWS customers understand how their machine learning models make predictions and build trust in their models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Clarify configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='LABEL',\n",
    "                                      headers=df.columns.to_list(),\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelPredictedLabelConfig` provides information on the format of your predictions. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1 and below or equal as label value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure a job with SageMaker Clarify, you must specify the following input parameters: the sensitive columns (`facets`) ,  the sensitive features (`facet_values_or_threshold`), and the desirable outcomes for bias metrics (`label_values_or_threshold`). SageMaker Clarify can handle both categorical and continuous data for `facet_values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "\n",
    "We specify this information in the BiasConfig API. Here we use `SEX` as the sensitive group,  i.e. the group that is used to measure bias against. \n",
    "\n",
    "group_name is used to form subgroups for the measurement of Conditional Demographic Disparity in Labels (CDDL) and Conditional Demographic Disparity in Predicted Labels (CDDPL) with regards to Simpsonâs paradox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[0],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[1],\n",
    "                                group_name='AGE'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Post-training Bias\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with `run_pre_training_bias()` and `run_post_training_bias()` or at the same time with `run_bias()` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to run clarify job\n",
    "# clarify_processor.run_bias(data_config=bias_data_config,\n",
    "#                            bias_config=bias_config,\n",
    "#                            model_config=model_config,\n",
    "#                            model_predicted_label_config=predictions_config,\n",
    "#                            pre_training_methods='all',\n",
    "#                            post_training_methods='all')\n",
    "\n",
    "# clarify_bias_job_name = clarify_processor.latest_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clarify_bias_job_name' in locals():\n",
    "    s3_client.download_file(Bucket=default_bucket,\n",
    "                            Key=f'{prefix}/clarify-output/bias/report.pdf',\n",
    "                            Filename='./output/bias_report.pdf')\n",
    "    print(f'Downloaded clarify report from previous Clarify job: {clarify_bias_job_name}')\n",
    "else:\n",
    "    print(f'Loading pre-generated analysis file...\\n')\n",
    "    \n",
    "display(\"Click link below to view the Clarify repot.\", FileLink(\"./output/bias_report.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Explaining Predictions\n",
    "\n",
    "There are expanding business needs and legislative regulations that require explanations of why a model made the decision it did. SageMaker Clarify uses SHAP to explain the contribution that each input feature makes to the final decision.\n",
    "\n",
    "Kernel SHAP algorithm requires a baseline (also known as background dataset). Baseline dataset type shall be the same as dataset_type of DataConfig, and baseline samples shall only include features. By definition, baseline should either be a S3 URI to the baseline dataset file, or an in-place list of samples. In this case we chose the latter, and put the first sample of the test dataset to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # un-comment the code below to run the whole job\n",
    "\n",
    "# shap_config = sagemaker.clarify.SHAPConfig(\n",
    "#     baseline=[X_train.median().values[1:].tolist()],\n",
    "#     num_samples=100,\n",
    "#     agg_method='mean_abs')\n",
    "\n",
    "# explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "#     s3_data_input_path=train_data_uri,\n",
    "#     s3_output_path=explainability_output_path,\n",
    "#     label='LABEL',\n",
    "#     headers=df.columns.to_list(),\n",
    "#     dataset_type='text/csv')\n",
    "\n",
    "# clarify_processor.run_explainability(\n",
    "#     data_config=explainability_data_config,\n",
    "#     model_config=model_config,\n",
    "#     explainability_config=shap_config)\n",
    "\n",
    "# clarify_expl_job_name = clarify_processor.latest_job.name\n",
    "# print(f'Clarify job {clarify_expl_job_name} ran successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download explainability output\n",
    "if 'clarify_expl_job_name' in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket   = default_bucket, \n",
    "        Key      = f'{prefix}/clarify-output/explainability/analysis.json', \n",
    "        Filename = './output/explainability_analysis.json'\n",
    "    )\n",
    "    print(f'Downloaded analysis from previous Clarify job: {clarify_expl_job_name}\\n')\n",
    "else:\n",
    "    print(f'Loading pre-generated analysis file...\\n')\n",
    "\n",
    "with open('./output/explainability_analysis.json', 'r') as f:\n",
    "        analysis_result = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert analysis result to dataframe\n",
    "my_dict = analysis_result['explanations']['kernel_shap'][\"label0\"]['global_shap_values']\n",
    "my_dict_sorted = {k: v for k, v in sorted(my_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.bar(range(len(my_dict_sorted)), list(my_dict_sorted.values()), align='center')\n",
    "plt.xticks(range(len(my_dict_sorted)), list(my_dict_sorted.keys()))\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_xlabel('SHAP Value (impact on model output)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy\n",
    "After you build and train your models, you can deploy them to get predictions in one of two ways:\n",
    "\n",
    "1. To set up a persistent endpoint to get predictions from your models, use Amazon SageMaker hosting services. \n",
    "2. To get predictions for an entire dataset, use SageMaker batch transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Create an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker supports configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way. In addition, the endpoint configuration describes the instance type required for model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f'DEMO-XGBoostEndpointConfig-{strftime(\"%Y-%m-%d\", gmtime())}'\n",
    "\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.t2.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f'Endpoint Config Arn: {create_endpoint_config_response[\"EndpointConfigArn\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you need to create the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f'DEMO-XGBoostEndpoint-{strftime(\"%Y-%m-%d\", gmtime())}'\n",
    "\n",
    "create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Real-time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one sample from test data\n",
    "sample = X_test.sample(1, random_state=random_state)\n",
    "test_input = ','.join([str(x) for x in sample.drop(columns=['LABEL']).values.flatten().tolist()])\n",
    "\n",
    "sample_label = sample['LABEL'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "results = predictor.predict(test_input, initial_args = {\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "\n",
    "print (f'Model predicted {round(prediction)} - Test label is {sample_label}\\nPredicted probablitity of default: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_best_estimator = sagemaker.estimator.Estimator.attach(tuner.best_training_job())\n",
    "\n",
    "sm_transformer = the_best_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    accept = 'text/csv',\n",
    "    output_path= batch_output\n",
    ")\n",
    "\n",
    "sm_transformer.transform(test_data_uri, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the batch transform job is complete, SageMaker creates the test.csv.out prediction data saved in the batch_output path, which should be in the following format: `s3://sagemaker-<region>-111122223333/demo-sagemaker-xgboost-adult-income-prediction/batch-prediction`. Run the following AWS CLI to download the output data of the batch transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp {batch_output} ./output/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from batch transform result\n",
    "y_pred = pd.read_csv('./output/test.csv.out', header=None)\n",
    "y_pred.columns = ['probability']\n",
    "\n",
    "# round the probabilities to get [0, 1]\n",
    "y_pred['prediction'] = y_pred['probability'].apply(round)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "y_test = X_test['LABEL']\n",
    "\n",
    "print(classification_report(y_true=y_test,\n",
    "                y_pred=y_pred['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test,  y_pred['probability'])\n",
    "auc = roc_auc_score(y_test, y_pred['probability'])\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (AUC = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Delete resources\n",
    "\n",
    "\n",
    "After running the demo, you should remove the resources which were created to avoid accruing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_boto_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "\n",
    "models = sagemaker_boto_client.list_models(NameContains=model_name, MaxResults=50)['Models']\n",
    "for m in models:\n",
    "    sagemaker_boto_client.delete_model(ModelName=m['ModelName'])\n",
    "    print(f\"\\nDeleted model: {m['ModelName']}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(default_bucket)\n",
    "bucket.objects.filter(Prefix=f\"{prefix}/\").delete()\n",
    "print(f\"\\nDeleted contents of {default_bucket}/{prefix}\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
